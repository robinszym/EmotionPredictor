# EmotionPredictor

The EmotionPredictor predicts the emotion distribution of images. It uses CLIP as backbone and a single linear unit model trained on the ArtEmis dataset.

# Image affect prediction
![example](https://github.com/robinszym/EmotionPredictor/blob/beta/example.jpeg?raw=true)

The model predicts the emotion distribution of images.
# Affective search
It is possible to perform affective search on images by imputing a text prompt and filtering with an emotion.


# Text affect
Since the model was trained with CLIP it is also possible to predict the affect of a word or a sentence. It's use for sentiment analysis is limited but is helpful for testing hypothesis on why the model predicts certain emotions. 

# About
This project was carried as part of my Master thesis at the IVRL lab of EPFL.



