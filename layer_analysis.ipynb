{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfa4c899-da61-43f4-97a2-038f65c4b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact \n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import clip\n",
    "from  torchvision import transforms as T\n",
    "\n",
    "from artemis.emotions import ARTEMIS_EMOTIONS\n",
    "import EmotionPredictor.data_tools as dt\n",
    "import  EmotionPredictor.visual as visual\n",
    "from EmotionPredictor.data_tools import get_loaders\n",
    "from EmotionPredictor.training import Trainer, SLP\n",
    "from EmotionPredictor.visual import save_fig\n",
    "\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b5f320-6ca8-43d2-8432-521c134bca2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Layer analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495f764d-6d13-4f36-a0c2-291e8e4e4027",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature extraction\n",
    "In this section a hook is attached to the botle necks of each layer of clip's ResNet50 to save their averaged output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1fe960c-c485-4776-91f5-97312c5d8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "resnet_clip, _ = clip.load(\"RN50\")\n",
    "resnet_clip = resnet_clip.eval()\n",
    "resnet_clip50 = resnet_clip.visual\n",
    "resnet50_dict = dict(resnet_clip50.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f516fdd9-9e6a-4699-8e2a-97d65dfd0b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backup at id : 140314852755728\n"
     ]
    }
   ],
   "source": [
    "def retrieve_backup(backup_id):\n",
    "    return [x for x in globals().values() if id(x)==backup_id][0]\n",
    "\n",
    "class HooksBackup:\n",
    "    \"\"\"Class made to backup the hooks to keep track of the hooks.\"\"\"\n",
    "    def __init__(self):\n",
    "        self._backup = {}\n",
    "        self._hook_managers = []\n",
    "        print(f\"backup at id : {id(self)}\")\n",
    "        \n",
    "    @property\n",
    "    def hook_managers(self):\n",
    "        return self._hook_managers\n",
    "    \n",
    "    @property\n",
    "    def backup(self):\n",
    "        return self._backup\n",
    "    \n",
    "    def flush(self):\n",
    "        for hook_manager in self._hook_managers:\n",
    "            hook_manager.remove_hooks()\n",
    "        self._hook_managers = []\n",
    "            \n",
    "    \n",
    "    def add_hook(self, layer, hook):\n",
    "        if layer in self._backup.keys():\n",
    "            self._backup[layer].append(hook)\n",
    "        else :\n",
    "            self._backup[layer] = [hook]\n",
    "\n",
    "        \n",
    "    def add_hook_manager(self, manager):\n",
    "        self._hook_managers.append(manager)\n",
    "        \n",
    "            \n",
    "_hooks_backup = HooksBackup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfc97890-f482-4682-af4f-f889261588ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HooksManager():\n",
    "    def __init__(self, layer_name, layer, hook_functions = None ):\n",
    "        self.outputs = {}\n",
    "        self._reset_hooks()\n",
    "        self.name = layer_name\n",
    "        self.layer = layer\n",
    "        self._hooks = []\n",
    "        self._hook_functions = hook_functions if hook_functions is not None else []\n",
    "        self.set_hooks()\n",
    "        _hooks_backup.add_hook_manager(self)\n",
    "        \n",
    "    @property\n",
    "    def hook_functions(self):\n",
    "        return self._hook_functions\n",
    "            \n",
    "    @hook_functions.setter      \n",
    "    def hook_functions(self, new_hook_functions):\n",
    "        self._hook_functions = new_hook_functions\n",
    "        self.remove_hooks()\n",
    "        self.set_hooks()\n",
    "        \n",
    "    def set_hooks(self):\n",
    "        for func in self._hook_functions:\n",
    "            new_hook = self.layer.register_forward_hook(func)\n",
    "            self._hooks.append(new_hook)\n",
    "            _hooks_backup.add_hook(self.layer, new_hook)\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        for hook in self._hooks :\n",
    "            hook.remove()\n",
    "        self._reset_hooks()\n",
    "\n",
    "    def _reset_hooks(self):\n",
    "        self._hooks = []\n",
    "\n",
    "def store_transformed_outputs(function, target):\n",
    "    \"\"\"Takes a hooking function and store its output in a target.\n",
    "    The target is a a dictionary of type {\"target\": target_destination} \"\"\"\n",
    "    def hooked(layer, input, output):\n",
    "        tensor = function(layer, input, output)\n",
    "        target[\"image\"] = tensor\n",
    "    return hooked\n",
    "    \n",
    "def average2d(tensor):\n",
    "    assert len(tensor.shape) == 4, f\"expected 4d input got {tenser.shape}\"\n",
    "    return tensor.mean((2,3))\n",
    "\n",
    "def average_my_output(layer, inp, output):\n",
    "    return average2d(output)\n",
    "\n",
    "def save_batch(batch_number, batch, save_path):\n",
    "    if not os.path.exists(save_path): os.mkdir(save_path)\n",
    "    with open(f\"{save_path}/batch{batch_number}.bin\",\"wb\") as f:\n",
    "            pickle.dump(batch, f)\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4bde25e-8920-4f66-b96e-af7059ad191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_forward_pass = {}\n",
    "layer_names = [f\"layer{i}\" for i in range(1,5)]\n",
    "data_path = \"../data/wikiart_embeddings/clip_training/RN50_layers/\"\n",
    "if not os.path.exists(data_path): os.mkdir(data_path)\n",
    "_hooks_backup.flush()\n",
    "for layer_name in layer_names: \n",
    "    for bottle_name, bottle_neck in resnet50_dict[layer_name].named_children():\n",
    "        name = layer_name + \"_\" + bottle_name\n",
    "        path = osp.join(data_path, name )\n",
    "        if not os.path.exists(path): os.mkdir(path)\n",
    "        stored_forward_pass[name] = {\"data_path\" : path, \n",
    "                                           \"image\": None}\n",
    "        hook_functions = [store_transformed_outputs(average_my_output, stored_forward_pass[name])]\n",
    "        HooksManager(name, bottle_neck, hook_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "deee5ca7-f642-49ac-b3a6-af8b01537b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_storage = dict(zip(layer_names, [{} for _ in layer_names]))\n",
    "_hooks_backup.flush()\n",
    "for name in layer_names:\n",
    "    hook_functions = [store_transformed_outputs(average_my_output, target_storage[name])]\n",
    "    HooksManager(name, resnet50_dict[name], hook_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afbe18a9-23a7-46d1-b20e-c5d90427d27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating val set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:23,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "199it [00:35,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating rest set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:02,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3372it [09:27,  5.94it/s]\n"
     ]
    }
   ],
   "source": [
    "for subset in [\"val\",\"test\", \"rest\", \"train\"]:\n",
    "    print(f\"creating {subset} set\")\n",
    "    dataloader = dt.Pickle_data_loader(f\"../_data/preprocessed/img_size_224/{subset}/\")\n",
    "    for i, batch in tqdm(enumerate(dataloader)):\n",
    "        resnet_clip50(batch[\"image\"])\n",
    "        for layer in stored_forward_pass.keys() :\n",
    "            batch[\"image\"] = stored_forward_pass[layer][\"image\"]\n",
    "            save_batch(i, batch, stored_forward_pass[layer][\"data_path\"] + f\"/{subset}\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9212f0-7462-4f70-b0e6-ef9e882c37a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Layer visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30865553-86e3-4294-92eb-fb9f0526f778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer3_4 created.\n",
      "layer1_2 created.\n",
      "layer2_1 created.\n",
      "layer3_1 created.\n",
      "layer2_0 created.\n",
      "layer2_3 created.\n",
      "layer2_2 created.\n",
      "layer1_0 created.\n",
      "layer4_2 created.\n",
      "layer3_0 created.\n",
      "layer3_2 created.\n",
      "layer4_0 created.\n",
      "layer3_5 created.\n",
      "layer3_3 created.\n",
      "layer1_1 created.\n",
      "layer4_1 created.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../data/wikiart_embeddings/clip_training/RN50_layers/\"\n",
    "checkpoint_path = \"../neural_checkpoints/clip_training/RN50_layers/\"\n",
    "models = {}\n",
    "base_layers = layer_names = [f\"layer{i}\" for i in range(1,5)] # [\"layer1\",\"layer2\",\"layer3\",\"layer4\"]\n",
    "layers = os.listdir(resnet_layer_path)\n",
    "for base_layer in base_layers : layers.remove(base_layer)\n",
    "def train_on_dataset(path):\n",
    "    \"\"\"Fix the parameters for training on the ArtEmis features\"\"\"\n",
    "    loaders = get_loaders(path)\n",
    "    input_shape = (loaders[\"train\"].load_batch(0))[\"image\"].shape[1]\n",
    "    return Trainer(model = SLP(input_size = input_shape, output_size=9).to(device),\n",
    "                        loss_fn = nn.BCEWithLogitsLoss(),\n",
    "                        optimizer_fn = torch.optim.Adam,\n",
    "                        lr = 10**-2,\n",
    "                        data_loaders = loaders,\n",
    "                        device = device)\n",
    "\n",
    "for layer in layers :\n",
    "    models[layer] = train_on_dataset(osp.join(dataset_path, layer))\n",
    "    print(layer + \" created.\")\n",
    "    if layer in os.listdir(checkpoint_path):\n",
    "        models[layer].model.load_state_dict(torch.load(osp.join(checkpoint_path, layer)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf41d071-f445-4002-a80a-eff4f28307f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.values():\n",
    "    model.train_eval(4, lrs = [10**-2,10**-3,10**-4,10**-5])\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd08970f-1a1f-4e3d-96dd-fc4bcd841ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.values() : model.create_report(ARTEMIS_EMOTIONS, show_fig = False)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf1b799e-6508-45d1-93e6-f55174b9ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, model in models.items():\n",
    "    model.save_model(osp.join(checkpoint_path, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f5d15c4-23b3-482f-aa82-8a9476b3468c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agreement_threshold</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>precision_recall_fscore_support</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>layer1_0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>amusement  awe  contentment  e...</td>\n",
       "      <td>([0.3786407766990291, 0.36065573770491804, 0.5...</td>\n",
       "      <td>0.193657</td>\n",
       "      <td>0.203543</td>\n",
       "      <td>0.532584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>amusement  awe  contentment  e...</td>\n",
       "      <td>([0.391304347826087, 0.36649214659685864, 0.57...</td>\n",
       "      <td>0.195471</td>\n",
       "      <td>0.205955</td>\n",
       "      <td>0.535230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          agreement_threshold  \\\n",
       "layer1_0                  0.5   \n",
       "layer1_1                  0.5   \n",
       "\n",
       "                                           confusion_matrix  \\\n",
       "layer1_0                  amusement  awe  contentment  e...   \n",
       "layer1_1                  amusement  awe  contentment  e...   \n",
       "\n",
       "                            precision_recall_fscore_support    recall  \\\n",
       "layer1_0  ([0.3786407766990291, 0.36065573770491804, 0.5...  0.193657   \n",
       "layer1_1  ([0.391304347826087, 0.36649214659685864, 0.57...  0.195471   \n",
       "\n",
       "          f1_score  accuracy  \n",
       "layer1_0  0.203543  0.532584  \n",
       "layer1_1  0.205955  0.535230  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[key, model.metrics()] for key, model in models.items()]\n",
    "index, vals = list(zip(*a))\n",
    "res_layers = pd.DataFrame(vals, index = index).sort_index()\n",
    "res_layers.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6197c8a2-3a8c-4fd5-9907-011181b2cf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5ce50027d6462f846f4712d685f46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='metric', options=('precision', 'recall', 'fscore'), value='precisi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prf2index = dict(list(zip([\"precision\", \"recall\", \"fscore\"], range(3))))\n",
    "\n",
    "@interact(metric = prf2index.keys())\n",
    "def plot_layers(metric):\n",
    "    f1s = res_layers[\"precision_recall_fscore_support\"].map(lambda y : y[prf2index[metric]])\n",
    "    f1s = pd.DataFrame(f1s)\n",
    "    for i, emotion in enumerate(ARTEMIS_EMOTIONS):\n",
    "        f1s[emotion] = f1s.precision_recall_fscore_support.map(lambda y : y[i])\n",
    "    f1s = f1s.drop(columns = \"precision_recall_fscore_support\")\n",
    "    \n",
    "    ax = f1s.plot(figsize = (16,9));\n",
    "    colors_emotions = visual.emotion_colors()\n",
    "    markers = ['>', '+', '.', ',', 'o', 'v', 'x', 'X', 'D', '|']\n",
    "    for i, line in enumerate(ax.get_lines()):\n",
    "        line.set_marker(markers[i])\n",
    "        line.set_color(colors_emotions[i])\n",
    "    ax.legend(ax.get_lines(), f1s.columns, loc='upper left')\n",
    "    plt.grid(axis = \"y\", ls = \":\")\n",
    "    plt.ylabel(\"f1 score\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
